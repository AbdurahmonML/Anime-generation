{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hXRIQCWMlJp"
      },
      "source": [
        "# Variational Autoencoder (VAE) Training and Image Generation\n",
        "This notebook demonstrates the training of a Variational Autoencoder (VAE) and generating new images using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ3uaapJMlJr",
        "outputId": "e18e22ed-f0f0-4315-8356-134d1b56cb91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\abdur\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\abdur\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
            "WARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
            "    torch (>=1.7.*)\n",
            "           ~~~~~~^\n",
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\abdur\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cFsBV15MlJs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import utils\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from vae_model import VAE, vae_loss\n",
        "from dataset import CustomDataset\n",
        "from train import train_vae\n",
        "from generate_images import generate_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6H0rGcMMlJs"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "data_dir = r'C:\\Users\\abdur\\Anime_generation\\VAE\\images'  # Update with your dataset path\n",
        "output_dir = './output'              # Output directory for model checkpoints\n",
        "latent_dim = 64                       # Latent dimension size\n",
        "batch_size = 128                      # Batch size for training\n",
        "learning_rate = 0.001                 # Learning rate for the optimizer\n",
        "num_epochs = 20                       # Number of training epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzvi1LYeMlJs",
        "outputId": "60c8cead-6a55-4f9b-a362-fdd05573b663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file and destination folder\n",
        "zip_path = r'C:\\Users\\abdur\\Anime_generation\\VAE\\archive.zip'\n",
        "output_folder = 'VAE\\extracted_images'\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Extract all images\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for file in zip_ref.namelist():\n",
        "        # Check if the file is an image by its extension\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
        "            zip_ref.extract(file, output_folder)\n",
        "\n",
        "print(\"Extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTkJo4SMMlJt"
      },
      "outputs": [],
      "source": [
        "# Train the VAE\n",
        "data_dir = r'C:\\Users\\abdur\\Anime_generation\\VAE\\images'\n",
        "train_vae(data_dir, output_dir, latent_dim, batch_size, learning_rate, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sz-NBXYfORwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take saved model\n",
        "generate_images(model_path, latent_dim=64, num_images=10)"
      ],
      "metadata": {
        "id": "XRjGsQp-N7ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}